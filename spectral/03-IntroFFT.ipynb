{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg; Pkg.activate(\".\")\n",
    "using Plots, LinearAlgebra, LaTeXStrings\n",
    "include(\"tools.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79cb3e3",
   "metadata": {},
   "source": [
    "# Introduction to the FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce1cb30",
   "metadata": {},
   "source": [
    "### Trigonometric Interpolation\n",
    "\n",
    "Trigonometric polynomials are functions of the form\n",
    "$$\n",
    "t_N(x) = \\sum_{k = -N}^N c_k e^{i k x}\n",
    "$$\n",
    "$N$ is called the degree of $t_N$. The space of all trigonometric polynomials of degree $N$ is denoted by \n",
    "$$\n",
    "\\mathcal{T}_N := {\\rm span}\\big\\{ x \\mapsto \\exp(i k x ) \\,|\\, k  = -N, \\dots, N \\big\\}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c77648",
   "metadata": {},
   "source": [
    "A general degree $N$ trigonometric polynomial, \n",
    "$$\n",
    "   t_N(x) = \\sum_{k = -N}^N c_k e^{i k x}\n",
    "$$\n",
    "has $2N+1$ parameters $c_{-N}, \\dots, c_N$. How should we determine these? It would be ideal if we can prescribe exactly $2N+1$ conditions. A natural and general approach is *interpolation*: given a target function $f \\in C_{\\rm per}$ we demand that \n",
    "$$ \n",
    "\tt_N(x_j) = f(x_j), \\qquad j = 0, \\dots, 2N\n",
    "$$\n",
    "where $x_j$ are called the interpolation nodes. \n",
    "\n",
    "How should they be chosen? It turns out  that equi-spaced nodes work very well. An intuitive justification for this choice is that in a periodic domain, all parts of the domain are \"equal\" and should be treated the same. By contrast in a finite interval one should *not* use equispaced nodes, but rather cluster them at the boundary (cf. Chebyshev interpolation [Trefethen, Ch. 4]). \n",
    "Because of the periodic boundary condition the nodes $x = 0, x = 2\\pi$ are \"equivalent\", in the sense that $f(0) = f(2\\pi)$, which is clearly a bad idea! A possibly way forward is to use the nodes $\\frac{2\\pi j}{2N+1}, j= 1, \\dots, 2N+1$. For algorithmic ideas it turns out that a much more convenient decision is the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a4a01",
   "metadata": {},
   "source": [
    "Start with the grid $x_j = \\pi j/N$, $j \\in \\mathbb{Z}$. This only gives $2N$ independent interpolation conditions, e.g. for $j = 0, \\dots, 2N-1$. The interpolation operator has an at least 1-dimensional kernel. Conveniently we can exactly characterize this kernel due to the fact that \n",
    "$$\n",
    "e^{i N x_j} = e^{-i N x_j},  \\qquad \\forall j \\in \\mathbb{Z}. \n",
    "$$\n",
    "Namely, \n",
    "$$\n",
    "   e^{i N x_j} = e^{i N j \\pi/N}  = e^{i\\pi j} \n",
    "  = (-1)^j = (-1)^{-j} = e^{-i \\pi j} = e^{- i N \\pi j/N} = e^{- i N x_j}.\n",
    "$$\n",
    "This suggests that we replace those two basis functions by their mean,\n",
    "$$\n",
    "\t\\frac{e^{i N x} + e^{-i N x}}{2} = \\cos(N x),\n",
    "$$\n",
    "\n",
    "Effectively it means that we've replaced the space $\\mathcal{T}_N$ of all trigonometric polynomials of degree $N$ with the sligtly smaller space \n",
    "$$\n",
    "\t\\mathcal{T}_N' := {\\rm span} \\Big( \\mathcal{T}_{N-1} \\cup \\{ \\cos(Nx) \\} \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e6daa",
   "metadata": {},
   "source": [
    "But remember that $\\cos(N x_j) = e^{i N x_j} = e^{- i N x_j}$ for all $x_j$, hence we can still write the interpolation conditions as \n",
    "$$\n",
    "\\sum_{k = -N+1}^N \\hat{F}_k e^{i \\pi k j / N} = F_j, \\qquad j = 0, \\dots, 2N-1,\n",
    "$$\n",
    "where $\\hat{F}_k$ are the unknown parmeters and $F_j = f(x_j)$ the nodal values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80327997",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** The ordering of the basis is in principle arbitrary. Here we use a convention used for fast algorithms (FFT), \n",
    "$$\n",
    "\t(0, 1, \\dots, N, -N+1, -N+2, \\dots, -1)\n",
    "$$\n",
    "This may look strange at first, but see more on this below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"interpolation nodes\"\n",
    "xgrid(N) = [ j * π / N  for j = 0:2N-1 ]\n",
    "\n",
    "\"fourier coefficient indices\"\n",
    "kgrid(N) = [ 0:N; -N+1:-1 ]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68cd4a",
   "metadata": {},
   "source": [
    "It turns out that the system matrix is orthogonal up to rescaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "# implement the nodal interpolation operator \n",
    "A = [ exp(im * k * x) for k in kgrid(N), x in xgrid(N) ]\n",
    "# observe that A'A ~ diagonal\n",
    "real.(round.(A' * A, digits=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b920a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm it is an orthogonal matrix (up to scaling)! I.e. (A'/2N) = inv(A) !!\n",
    "norm(A' * A - 2*N*I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ee6b5",
   "metadata": {},
   "source": [
    "In addition to guaranteeing that $I_N$ is well-defined we also see that the matrix $A$ we need to invert is orthogonal (up to rescaling), which makes it very easy to invert it. We just need to multiply by $A^H$, i.e. $O(N^2)$ computational cost instead of $O(N^3)$ for solving a full linear system via [Gaussian elimination](https://en.wikipedia.org/wiki/LU_decomposition).\n",
    "\n",
    "These two operations $F \\mapsto \\hat{F}$ and $\\hat{F} \\mapsto F$ are called the discrete and inverse discrete fourier transforms (up to scaling). They can in fact be applied with $O(N \\log(N))$ computational cost, using the *fast fourier transform*. We will discuss this below, but first use our naive implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996278aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "construct the coefficients of the trigonometric interpolant\n",
    "\"\"\"\n",
    "function triginterp(f, N)\n",
    "    X = xgrid(N)\n",
    "    # nodal values at interpolation nodes\n",
    "    F = f.(X) \n",
    "    # system matrix\n",
    "    A = [ exp(im * x * k) for k in kgrid(N), x in X ]\n",
    "    # coefficients are given by F̂ = A' * F as discussed above!\n",
    "    return (A' * F) / (2*N)\n",
    "end \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "to evaluate a trigonometric polynomial just sum coefficients * basis\n",
    "we the take the real part because we assume the function we are \n",
    "approximating is real.\n",
    "\"\"\"\n",
    "evaltrig(x, F̂) = sum( real(F̂k * exp(im * x * k))\n",
    "                      for (F̂k, k) in zip(F̂, kgrid(length(F̂) ÷ 2)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4e8f2",
   "metadata": {},
   "source": [
    "### The Fast Fourier Transform \n",
    "\n",
    "Recall from above that the trigonometric interpolant $I_N f$ of a function $f$ is given by\n",
    "$$\n",
    "\tI_N f(x) = \\sum_{k = -N+1}^{N-1} \\hat{F}_k e^{i k x} + \\hat{F}_N \\cos(N x)\n",
    "$$\n",
    "and the coefficients are determined by the linear system \n",
    "$$\n",
    "\t\\sum_{k = -N+1}^N \\hat{F}_k e^{i k x_j} = F_j, \\qquad j = 0, \\dots, 2N-1.\n",
    "$$\n",
    "where $F_j = f(x_j)$ and $x_j = j \\pi / N$. We have moreover shown numerically (to be proven in assignment) that the system matrix is orthogonal (up to rescaling), i.e., if \n",
    "$$\n",
    "\tA = \\big( e^{i k x_j} \\big)_{k,j}\n",
    "$$\n",
    "then \n",
    "$$\n",
    "\tA A^H = 2N I\n",
    "$$\n",
    "In particular $A$ is invertible, i.e., the mapping $F \\mapsto \\hat{F}, \\mathbb{C}^{2N} \\to \\mathbb{C}^{2N}$ is invertible. \n",
    "This mapping is called the discrete fourier transform (DFT) and its inverse is called the inverse discrete fourier transform (IDFT, $\\hat{F} \\mapsto F$). Both use a different scaling than we use here; specifically, the most commen definition is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t{\\rm DFT}[G]_k &= \\sum_{j = 0}^{2N-1} e^{- i k j \\pi / N} G_j, \\\\ \n",
    "\t{\\rm IDFT}[\\hat{G}]_j &= \\frac{1}{2N} \\sum_{k = -N+1}^N e^{i k j \\pi / N} \\hat{G}_k.\n",
    "\\end{aligned}\n",
    "$$\n",
    "This means the the mappings $F \\mapsto \\hat{F}, \\hat{F} \\mapsto F$ can be written as \n",
    "$$\n",
    "\t\\hat{F} = (2N)^{-1} \\cdot {\\rm DFT}[F], \\qquad F = 2N \\cdot {\\rm IDFT}[\\hat{F}]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58934e3",
   "metadata": {},
   "source": [
    "The cost of evaluating the DFT and IDFT naively is $O(N^2)$ (matrix-vector multiplication) but the special structures in the DFT make it possible to evaluate them in $O(N \\log (N))$ operations. This was first observed by Gauss (1876), and much later rediscovered and popularized by [Cooley & Tukey (1965)](https://en.wikipedia.org/wiki/Cooley–Tukey_FFT_algorithm). It is generally considered one of the [most important algorithms of the 20th century](https://www.computer.org/csdl/magazine/cs/2000/01/c1022/13rRUxBJhBm). \n",
    "\n",
    "In Julia, the FFT is implemented in the [FFTW package](https://github.com/JuliaMath/FFTW.jl) (the Fastest Fourier Transform in the West). Before we study it, we can try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c57d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using FFTW\n",
    "\n",
    "function dft(F)\n",
    "    N = length(F) ÷ 2\n",
    "    A = [ exp(im * k * x) for k in kgrid(N), x in xgrid(N) ]\n",
    "    return (A' * F) / (2*N)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33232a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "?fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a random tests to confirm FFT = DFT\n",
    "N = 128\n",
    "F = rand(ComplexF64, N)\n",
    "norm( dft(F) - fft(F) / N )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d518a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128\n",
    "# run a random test to see how fft, ifft work\n",
    "F = rand(ComplexF64, N)\n",
    "norm(F - ifft(fft(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94723e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_dft = [ 8, 16, 32, 64, 128 ] \n",
    "NN_fft = [ 8, 16, 32, 64, 128, 256, 512, 1024, 2048 ] \n",
    "FF = [ rand(ComplexF64, 2*N) for N in NN_fft ]   # random trial vectors \n",
    "times_dft = [ (@belapsed dft($(FF[n]))) for n = 1:length(NN_dft) ]\n",
    "times_fft = [ (@belapsed fft($(FF[n]))) for n = 1:length(NN_fft) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded853e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(NN, times_dft, label = \"DFT\", lw=2, xscale = :log10, yscale=:log10, m=:o, ms=5)\n",
    "\n",
    "plot(NN_dft, times_dft, lw=2, m=:o, label = \"DFT\", \n",
    "     xscale = :log10, yscale=:log10, ylims = (1e-6, 3e-3), \n",
    "    size = (400, 300), xlabel = \"N\", ylabel = \"runtime [s]\")\n",
    "plot!(NN_fft, times_fft, lw=2, m=:o, label = \"DFT\")\n",
    "plot!(NN_dft, 1e-7*NN_dft.^2, lw=1, ls=:dash, c=:black, label = L\"N^2, N\")\n",
    "plot!(NN_fft, 3e-8*NN_fft, lw=1, ls=:dash, c=:black, label = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96319528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
